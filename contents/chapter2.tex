\chapter{Kajian Pustaka}

\section{State of The Art}

\vspace{-1cm}
\begin{longtable}[t]
  {@{}
    |>{\raggedright\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{.25}}
    |>{\raggedright\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{.25}}
    |>{\raggedright\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{.25}}
    |>{\raggedright\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{.25}}|
  @{}}
  \endhead
  \endlastfoot

  \caption{State of The Art} \\

  \hline
  \textbf{Judul Penelitian} &
  \textbf{Metrik} &
  \textbf{Metode Penelitian} &
  \textbf{Hasil}

  \\ \hline
  {Web Application Development for Biometric Identification System Based on Neural Network Face Recognition \parencite{bykovWebApplicationDevelopment2020}} &
  {Akurasi deteksi wajah, System Response.} &
  {Pengembangan aplikasi web berbasis neural network untuk identifikasi wajah dengan arsitektur MVC dan pengujian performa modul.} &
  {Kompleks identifikasi biometrik berhasil diterapkan di lingkungan keamanan seperti bandara dengan akurasi tinggi.}


  \\ \hline
  {Real time Face Detection and Optimal Face Mapping for Online Classes \parencite{archanaRealTimeFace2022}} &
  {Akurasi deteksi wajah, ~Attendance reliability, Real-Time Performance.} &
  {Perbandingan algoritma Local Binary Pattern Histogram (LBPH) dan Convolutional Neural Network (CNN) untuk pengenalan wajah serta Haar Cascade untuk deteksi wajah.} &
  {Algoritma CNN memiliki akurasi 95\%, lebih tinggi dibandingkan LBPH (78\%), menunjukkan keunggulan untuk kehadiran real-time dalam kelas online.}

  \\ \hline
  {Web Front-End Realtime Face Recognition Based on TFJS \parencite{liWebFrontEndRealtime2019}} &
  {Latency, Kecepatan deteksi wajah.} &
  {Implementasi pengenalan wajah di browser menggunakan TensorFlow.js dan pengujian pada berbagai skenario untuk mengurangi beban server.} &
  {Sistem pengenalan wajah Real-Time di sisi Client berhasil menurunkan latensi dan beban Server, menunjukkan respons yang dapat diterima pengguna.}

  \\ \hline
  {Web Performance Optimization Techniques for Biodiversity Resource Portal \parencite{budimanWebPerformanceOptimization2019}} &
  {Efficiency Score, Load Lime, Page Rank, End-to-End Performance Indicators.} &
  {Analisis sebelum dan pasca-optimasi menggunakan teknik Web Performance Optimization (WPO), dinilai dengan GTmetrix.} &
  {Peningkatan signifikan dalam performa portal, dari Grade F (13\%) menjadi Grade B (82\%) setelah optimasi.}

  \\ \hline
  {WebSocket in real time application \parencite{ogundeyiWebSocketRealTime2019}} &
  {Latency, Efficiency, Data Transmission Reliability } &
  {Analisis performa WebSocket dibandingkan dengan HTTP
  long polling dan server-sent events untuk aplikasi real-time.} &
  {WebSocket memberikan performa yang lebih baik dalam latensi dan efisiensi jaringan, mendukung pertukaran data dua arah yang lebih halus untuk aplikasi real-time.}

  \\ \hline
  {PROPOSED} &
  {Memory Usage, System Responses, Real-Time Performance.} &
  {Uji coba aplikasi dan web server pada aplikasi web virtual meeting untuk menguji performa.} &
  {Menganalisis cara meengoptimalkan kecepatan, keakuratan, dan efektivitas sistem analisis ekspresi wajah berbasis face recognition dan socket communication}

  \\ \hline

\end{longtable}

\newpage

\section{High Availability}
High Availability (HA) adalah konsep desain sistem yang bertujuan untuk memastikan tingkat ketersediaan operasional yang tinggi dan berkelanjutan, biasanya mendekati 100\%.
Tujuan utama dari arsitektur HA adalah untuk menghilangkan satu titik kegagalan (Single Point of Failure) dalam infrastruktur, sehingga sistem dapat terus berfungsi meskipun terjadi kegagalan pada salah satu komponennya.
Strategi umum untuk mencapai HA meliputi redundansi, di mana komponen kritis seperti server, basis data, dan load balancer diduplikasi, serta mekanisme failover otomatis yang mengalihkan lalu lintas dari komponen yang gagal ke komponen cadangan tanpa intervensi manual.
Dengan demikian, layanan tetap dapat diakses oleh pengguna dengan downtime minimal atau bahkan tanpa downtime sama sekali.

\section{Auto Scalability}
Auto scalability, atau skalabilitas otomatis, adalah kemampuan sistem untuk secara dinamis menyesuaikan alokasi sumber daya komputasi berdasarkan permintaan lalu lintas saat ini.
Dalam lingkungan cloud seperti Google Cloud Platform (GCP), fitur ini memungkinkan aplikasi untuk secara otomatis menambah (scale-out) atau mengurangi (scale-in) jumlah server atau sumber daya lainnya.
Mekanisme ini memastikan bahwa aplikasi memiliki kapasitas yang cukup untuk menangani lonjakan lalu lintas tanpa mengalami penurunan performa, sekaligus mengoptimalkan biaya dengan mengurangi sumber daya saat permintaan rendah.
Implementasi auto scalability sering kali menggunakan layanan seperti Managed Instance Groups (MIGs) di Google Compute Engine atau Horizontal Pod Autoscaler (HPA) di Google Kubernetes Engine (GKE).

\section{Zero Downtime Deployment}
Zero Downtime Deployment adalah strategi penerapan (deployment) yang memungkinkan pembaruan perangkat lunak atau aplikasi dilakukan tanpa mengganggu ketersediaan layanan bagi pengguna.
Tujuannya adalah untuk merilis versi baru secara mulus sehingga transisi dari versi lama ke versi baru tidak terlihat oleh pengguna akhir.
Terdapat beberapa teknik populer untuk mencapai ini, seperti Blue-Green Deployment, di mana dua lingkungan produksi identik disiapkan secara paralel, dan lalu lintas dialihkan ke lingkungan baru setelah pengujian selesai.
Teknik lainnya adalah Canary Release, di mana pembaruan dirilis secara bertahap ke sebagian kecil pengguna sebelum diluncurkan sepenuhnya, serta Rolling Update, yang memperbarui instance satu per satu.

\section{Google Cloud Platform (GCP)}
Google Cloud Platform (GCP) adalah serangkaian layanan komputasi awan yang ditawarkan oleh Google.
GCP menyediakan infrastruktur yang andal, skalabel, dan aman untuk membangun, menerapkan, dan mengelola aplikasi di seluruh dunia.
Platform ini menawarkan berbagai layanan yang mendukung implementasi arsitektur modern, termasuk Google Kubernetes Engine (GKE) untuk orkestrasi kontainer, Cloud Load Balancing untuk distribusi lalu lintas yang efisien, dan Managed Instance Groups (MIGs) untuk manajemen dan skalabilitas otomatis pada mesin virtual.
Dengan memanfaatkan layanan-layanan ini, pengembang dapat membangun sistem yang memiliki ketersediaan tinggi, skalabilitas otomatis, dan kemampuan untuk melakukan zero downtime deployment, yang sangat penting untuk aplikasi kritis bisnis seperti platform EMODU.
